{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa659b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 1: PATH SETUP\n",
    "# =========================\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Notebook is running from: training/\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "# Add backend folder to Python path\n",
    "BACKEND_DIR = os.path.abspath(os.path.join(BASE_DIR, \"../backend\"))\n",
    "sys.path.append(BACKEND_DIR)\n",
    "\n",
    "print(\"Current working directory:\", BASE_DIR)\n",
    "print(\"Backend path added:\", BACKEND_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ee6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 2: CORE IMPORTS\n",
    "# =========================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"NumPy version:\", np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7132e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 3: IMPORT BACKEND MODULES\n",
    "# =========================\n",
    "from app.asr.speech_to_text import SpeechToText\n",
    "from app.features.grammar_features import extract_grammar_features\n",
    "\n",
    "print(\"Backend modules imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47096918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 4: DATASET PATHS\n",
    "# =========================\n",
    "import os\n",
    "\n",
    "# Notebook is running from: training/\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "DATASET_DIR = os.path.join(BASE_DIR, \"dataset\")\n",
    "AUDIO_DIR = os.path.join(DATASET_DIR, \"speech_data\")\n",
    "LABEL_FILE = os.path.join(DATASET_DIR, \"processed_audio_sample_scoring.xlsx\")\n",
    "\n",
    "print(\"Dataset dir exists :\", os.path.exists(DATASET_DIR))\n",
    "print(\"Audio dir exists   :\", os.path.exists(AUDIO_DIR))\n",
    "print(\"Label file exists  :\", os.path.exists(LABEL_FILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654a0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 5: LOAD LABEL FILE\n",
    "# =========================\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(LABEL_FILE)\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(\"Total samples:\", len(df))\n",
    "print(\"\\nColumns found:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Validate required columns\n",
    "required_columns = [\"Record Audio Name\", \"Content\"]\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 6: INITIALIZE ASR\n",
    "# =========================\n",
    "asr = SpeechToText(model_size=\"base\")\n",
    "\n",
    "print(\"ASR model initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 7 (FINAL + VISUALIZER): GENERATE TRANSCRIPTS\n",
    "# =========================\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Build lookup of audio files (without extension)\n",
    "audio_files = os.listdir(AUDIO_DIR)\n",
    "\n",
    "audio_lookup = {}\n",
    "for file in audio_files:\n",
    "    base = os.path.splitext(file)[0]\n",
    "    audio_lookup[base] = file\n",
    "\n",
    "print(\"Total audio files found:\", len(audio_lookup))\n",
    "\n",
    "transcripts = []\n",
    "missing_audio = 0\n",
    "\n",
    "# tqdm gives a live progress bar\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Transcribing audio\"):\n",
    "    excel_name = row[\"Record Audio Name\"]\n",
    "\n",
    "    audio_file = audio_lookup.get(excel_name)\n",
    "\n",
    "    if audio_file is None:\n",
    "        transcripts.append(\"\")\n",
    "        missing_audio += 1\n",
    "        continue\n",
    "\n",
    "    audio_path = os.path.join(AUDIO_DIR, audio_file)\n",
    "    text = asr.transcribe(audio_path)\n",
    "    transcripts.append(text)\n",
    "\n",
    "df[\"transcript\"] = transcripts\n",
    "\n",
    "print(\"✅ Transcription completed\")\n",
    "print(\"❌ Missing audio files:\", missing_audio)\n",
    "\n",
    "df[[\"Record Audio Name\", \"transcript\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ce320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 8 (WITH PROGRESS): GRAMMAR FEATURE EXTRACTION\n",
    "# =========================\n",
    "from tqdm import tqdm\n",
    "\n",
    "feature_rows = []\n",
    "\n",
    "for text in tqdm(df[\"transcript\"], total=len(df), desc=\"Extracting grammar features\"):\n",
    "    features = extract_grammar_features(text)\n",
    "    feature_rows.append(features)\n",
    "\n",
    "X = pd.DataFrame(feature_rows)\n",
    "y = df[\"Content\"]\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037b0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 9: TRAIN MODEL\n",
    "# =========================\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Validation size:\", X_val.shape)\n",
    "\n",
    "# Model\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "print(\"MAE:\", round(mae, 3))\n",
    "print(\"RMSE:\", round(rmse, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7337bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 10: SAVE MODEL & METADATA\n",
    "# =========================\n",
    "import joblib\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Create model directory if not exists\n",
    "MODEL_DIR = \"../backend/app/model\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Save trained model\n",
    "model_path = os.path.join(MODEL_DIR, \"grammar_scorer.pkl\")\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Save feature names (very important for inference)\n",
    "feature_metadata = {\n",
    "    \"features\": list(X.columns),\n",
    "    \"target\": \"Content\",\n",
    "    \"model\": \"RandomForestRegressor\",\n",
    "    \"mae\": mae,\n",
    "    \"rmse\": rmse\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(MODEL_DIR, \"metadata.json\")\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    json.dump(feature_metadata, f, indent=2)\n",
    "\n",
    "print(\"✅ Model saved to:\", model_path)\n",
    "print(\"✅ Metadata saved to:\", metadata_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094bfbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CELL 11: END-TO-END INFERENCE PIPELINE (FIXED PATH)\n",
    "# =========================\n",
    "import joblib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Correct model directory\n",
    "MODEL_DIR = r\"D:\\SHL\\backend\\app\\model\"\n",
    "MODEL_PATH = os.path.join(MODEL_DIR, \"grammar_scorer.pkl\")\n",
    "META_PATH = os.path.join(MODEL_DIR, \"metadata.json\")\n",
    "\n",
    "# Load model and metadata\n",
    "model = joblib.load(MODEL_PATH)\n",
    "with open(META_PATH, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "FEATURE_COLUMNS = metadata[\"features\"]\n",
    "\n",
    "print(\"✅ Model and metadata loaded successfully\")\n",
    "print(\"✅ Features used:\", FEATURE_COLUMNS)\n",
    "\n",
    "\n",
    "def score_audio(audio_path: str) -> float:\n",
    "    \"\"\"\n",
    "    Complete grammar scoring pipeline:\n",
    "    audio -> transcript -> grammar features -> score\n",
    "    \"\"\"\n",
    "    # 1. Speech to text\n",
    "    transcript = asr.transcribe(audio_path)\n",
    "\n",
    "    # 2. Grammar feature extraction\n",
    "    features = extract_grammar_features(transcript)\n",
    "\n",
    "    # 3. Ensure correct feature order\n",
    "    X_input = pd.DataFrame([features])[FEATURE_COLUMNS]\n",
    "\n",
    "    # 4. Predict score\n",
    "    score = model.predict(X_input)[0]\n",
    "\n",
    "    return round(float(score), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef43cfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.57"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_audio(r\"D:\\SHL\\training\\en-IN_Kajal_1700049178365.mp3\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
